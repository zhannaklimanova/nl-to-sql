\section{Results}
% Results: Report the results of your experiment, and any general trends that you see. If the
% evaluation measure used is not a standard one, be sure to define that as well.

% Users of older versions of \LaTeX{} may encounter the following error during compilation:
% \begin{quote}
% \tt\verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
% \end{quote}
% The evaluation metric


% SQL is Turing complete and this is the equivalence problem so, in the general case, it's not possible to know whether two queries will have the same output without running the SQL queries against sample data. This might be possible in limited, real-world cases but I believe you will quickly find it much trickier than expected.

0. Results from different schemas were used: schema with database terms not included, schema without database terms. And what is excluded from the schema with database terms not included (chants)...
1. INclude snippets of gold and predicted outputs sql.
2. Include predicted vs. gold outputs
3. three different metrics.

Table 1. schema with data
rows for each of the models
columns are the 3 different metrics: 1. Percent correct values, 2. unordered evaluation (take all id values and ordering and comparing if its the same or not (order is not taken into account) 3. ordered evaluation (can only do it with the one that match identically - do some research and if not good method do our own way)

Table 2. schema without data
rows for each of the models
columns are the 3 different metrics: 1. Percent correct values, 2. unordered evaluation (take all id values and ordering and comparing if its the same or not (order is not taken into account) 3. ordered evaluation (can only do it with the one that match identically - do some research and if not good method do our own way)
(ZHANNA)